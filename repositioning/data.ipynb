{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drug_iddict        final_Virus_DTI_add_organism.tsv  human_seq_dict.pkl    VDTI_net.npy           virusseq_add_ncov.pkl\n",
    "#drug_info.tsv      HDTI_net.npy                      human_seq_iddict.pkl  VHI_net.npy            virusseq_add_ncovseqdict.pkl\n",
    "#Drug_simi_net.npy  human.npy                         PPI_net.npy           virusseq_add_ncov.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPY\n",
    "drug_simi_net = np.load(\"DTI-data/Drug_simi_net.npy\")\n",
    "print(drug_simi_net.shape)\n",
    "print(drug_simi_net[0])\n",
    "HDTI_net = np.load(\"DTI-data/HDTI_net.npy\")\n",
    "print(HDTI_net.shape)\n",
    "print(HDTI_net[0])\n",
    "human = np.load(\"DTI-data/human.npy\")\n",
    "print(human.shape)\n",
    "print(human[0])\n",
    "ppi_net = np.load(\"DTI-data/PPI_net.npy\")\n",
    "print(ppi_net.shape)\n",
    "print(ppi_net[0])\n",
    "#This is our ultimate target\n",
    "vdti_net = np.load(\"DTI-data/VDTI_net.npy\")\n",
    "print(\"!\", vdti_net.shape)\n",
    "print(\"!\", vdti_net[0])\n",
    "vhi_net = np.load(\"DTI-data/VHI_net.npy\")\n",
    "print(vhi_net.shape)\n",
    "print(vhi_net[0])\n",
    "virusseq_add_ncov = np.load(\"DTI-data/virusseq_add_ncov.npy\")\n",
    "print(virusseq_add_ncov.shape)\n",
    "print(virusseq_add_ncov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PICKLE\n",
    "with open(\"DTI-data/human_seq_dict.pkl\", 'rb') as f:\n",
    "    human_seq_dict = pickle.load(f)\n",
    "with open(\"DTI-data/human_seq_iddict.pkl\", 'rb') as f:    \n",
    "    human_seq_iddict = pickle.load(f)\n",
    "with open(\"DTI-data/virusseq_add_ncov.pkl\", 'rb') as f:\n",
    "    virusseq_add_ncov = pickle.load(f)\n",
    "with open(\"DTI-data/virusseq_add_ncovseqdict.pkl\", 'rb') as f:\n",
    "    virusseq_add_ncovseqdict = pickle.load(f)\n",
    "with open(\"DTI-data/drug_iddict\", 'rb') as f:\n",
    "    drug_iddict = pickle.load(f)\n",
    "\n",
    "print(human_seq_dict[list(human_seq_dict.keys())[0]][:100], \"\\n\")\n",
    "print(human_seq_iddict[list(human_seq_iddict.keys())[0]], \"\\n\")\n",
    "print(virusseq_add_ncov[list(virusseq_add_ncov.keys())[0]], \"\\n\")\n",
    "print(virusseq_add_ncovseqdict[list(virusseq_add_ncovseqdict.keys())[0]][:100], \"\\n\")\n",
    "print(drug_iddict[list(drug_iddict.keys())[0]], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TSV\n",
    "with open(\"DTI-data/drug_info.tsv\", \"r\") as f:\n",
    "    drug_info = csv.reader(f, delimiter = '\\t')\n",
    "    drug_info = list(drug_info)\n",
    "with open(\"DTI-data/final_Virus_DTI_add_organism.tsv\", \"r\") as f:\n",
    "    final_Virus_DTI_add_organism = csv.reader(f, delimiter = '\\t') \n",
    "    final_Virus_DTI_add_organism = list(final_Virus_DTI_add_organism)\n",
    "\n",
    "print(drug_info[0:2])\n",
    "print(\"\")\n",
    "print(final_Virus_DTI_add_organism[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KnowledgeGraphEmbedding expects 5 files\n",
    "\n",
    "# entities.dict - maps entities to ids\n",
    "# relations.dict - maps relations to ids\n",
    "# train.txt - entity id to relation id\n",
    "# valid.txt - can be blank\n",
    "# test.txt\n",
    "\n",
    "print(HDTI_net.shape)\n",
    "print(HDTI_net[0])\n",
    "\n",
    "print(\"!\", vdti_net.shape)\n",
    "print(\"!\", vdti_net[0])\n",
    "\n",
    "print(vhi_net.shape)\n",
    "print(vhi_net[0])\n",
    "\n",
    "#entities.dict\n",
    "\n",
    "DRUG_COUNT = 6255\n",
    "HUMAN_COUNT = 2567\n",
    "VIRUS_COUNT = 404\n",
    "\n",
    "sum_ = DRUG_COUNT + HUMAN_COUNT + VIRUS_COUNT\n",
    "\n",
    "HUMAN_OFFSET = 6255\n",
    "VIRUS_OFFSET = 6255 + 2567\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/entities.dict\", \"w\") as f:\n",
    "    cnt = 0\n",
    "    for i in range(DRUG_COUNT + HUMAN_COUNT + VIRUS_COUNT):\n",
    "        f.write(str(i) + \"\\t\" + str(i) + \"\\n\")\n",
    "        cnt += 1\n",
    "    print(cnt)\n",
    "    print(sum_)\n",
    "    assert(cnt == sum_)\n",
    "\n",
    "#relations.dict\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/relations.dict\", \"w\") as f:\n",
    "    f.write(\"0\\t0\\n\")\n",
    "    f.write(\"1\\t1\\n\")\n",
    "    f.write(\"2\\t2\")\n",
    "#with open(\"KnowledgeGraphEmbedding/data/C-19/entities.dict\" as f):\n",
    "\n",
    "#all.txt\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/all.dict\", \"w\") as f:\n",
    "    #drug -> human\n",
    "\n",
    "    for (i, j), r in np.ndenumerate(HDTI_net):\n",
    "        assert(j + HUMAN_OFFSET < sum_)\n",
    "        if v:\n",
    "            f.write(str(i) + \"\\t\" + \"0\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "    #drug -> virus\n",
    "    i = 0\n",
    "    for (i, j), v in np.ndenumerate(vdti_net):\n",
    "        if v:\n",
    "            f.write(str(i) + \"\\t\" + \"1\"  + \"\\t\" +  str(j + VIRUS_OFFSET) + \"\\n\")  \n",
    "\n",
    "    #virus -> human\n",
    "    i = 0\n",
    "    for (i, j), r in np.ndenumerate(vhi_net):\n",
    "        assert(i + VIRUS_OFFSET < sum_)\n",
    "        assert(j + HUMAN_OFFSET < sum_)\n",
    "        if v:\n",
    "            f.write(str(i + VIRUS_OFFSET) + \"\\t\" + \"2\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")          \n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.85\n",
    "TRAIN_VAL_SPLIT  = 0.90\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/all.dict\", \"r\") as f:\n",
    "    lst = f.readlines()\n",
    "    train_t = random.sample(lst, int(len(lst) * TRAIN_TEST_SPLIT))\n",
    "    train   = random.sample(train_t, int(len(train_t) * TRAIN_VAL_SPLIT))\n",
    "    val     = [e for e in train_t if e not in train]\n",
    "    test    = [e for e in lst     if e not in train_t]\n",
    "    #train.txt\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/train.txt\", \"w+\") as f:\n",
    "        f.writelines(train)\n",
    "    #valid.txt\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/valid.txt\", \"w+\") as f:\n",
    "        f.writelines(val)\n",
    "    #test.txt\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/test.txt\",  \"w+\") as f:\n",
    "        f.writelines(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test\n",
    "\n",
    "!CUDA_VISIBLE_DEVICES=0 python -u KnowledgeGraphEmbedding/codes/run.py --do_train \\\n",
    " --cuda \\\n",
    " --do_valid \\\n",
    " --do_test \\\n",
    " --data_path KnowledgeGraphEmbedding/data/C-19 \\\n",
    " --model RotatE \\\n",
    " -n 256 -b 1024 -d 1000 \\\n",
    " -g 24.0 -a 1.0 -adv \\\n",
    " -lr 0.0001 --max_steps 150000 \\\n",
    " -save KnowledgeGraphEmbedding/models/RotatE_C-19_0 --test_batch_size 16 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitdeeplearningcondabb63992eb3684dd0924ac6194c142535",
   "display_name": "Python 3.7.6 64-bit ('deep-learning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}