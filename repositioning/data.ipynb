{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drug_iddict        final_Virus_DTI_add_organism.tsv  human_seq_dict.pkl    VDTI_net.npy           virusseq_add_ncov.pkl\n",
    "#drug_info.tsv      HDTI_net.npy                      human_seq_iddict.pkl  VHI_net.npy            virusseq_add_ncovseqdict.pkl\n",
    "#Drug_simi_net.npy  human.npy                         PPI_net.npy           virusseq_add_ncov.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPY\n",
    "drug_simi_net = np.load(\"DTI-data/Drug_simi_net.npy\")\n",
    "print(drug_simi_net.shape)\n",
    "print(drug_simi_net[0])\n",
    "HDTI_net = np.load(\"DTI-data/HDTI_net.npy\")\n",
    "print(HDTI_net.shape)\n",
    "print(HDTI_net[0])\n",
    "human = np.load(\"DTI-data/human.npy\")\n",
    "print(human.shape)\n",
    "print(human[0])\n",
    "ppi_net = np.load(\"DTI-data/PPI_net.npy\")\n",
    "print(ppi_net.shape)\n",
    "print(ppi_net[0])\n",
    "#This is our ultimate target\n",
    "vdti_net = np.load(\"DTI-data/VDTI_net.npy\")\n",
    "print(\"!\", vdti_net.shape)\n",
    "print(\"!\", vdti_net[0])\n",
    "vhi_net = np.load(\"DTI-data/VHI_net.npy\")\n",
    "print(vhi_net.shape)\n",
    "print(vhi_net[0])\n",
    "virusseq_add_ncov = np.load(\"DTI-data/virusseq_add_ncov.npy\")\n",
    "print(virusseq_add_ncov.shape)\n",
    "print(virusseq_add_ncov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PICKLE\n",
    "with open(\"DTI-data/human_seq_dict.pkl\", 'rb') as f:\n",
    "    human_seq_dict = pickle.load(f)\n",
    "with open(\"DTI-data/human_seq_iddict.pkl\", 'rb') as f:    \n",
    "    human_seq_iddict = pickle.load(f)\n",
    "with open(\"DTI-data/virusseq_add_ncov.pkl\", 'rb') as f:\n",
    "    virusseq_add_ncov_dict = pickle.load(f)\n",
    "with open(\"DTI-data/virusseq_add_ncovseqdict.pkl\", 'rb') as f:\n",
    "    virusseq_add_ncovseqdict = pickle.load(f)\n",
    "with open(\"DTI-data/drug_iddict\", 'rb') as f:\n",
    "    drug_iddict = pickle.load(f)\n",
    "\n",
    "print(human_seq_dict[list(human_seq_dict.keys())[0]][:100], \"\\n\")\n",
    "print(human_seq_iddict[list(human_seq_iddict.keys())[0]], \"\\n\")\n",
    "print(virusseq_add_ncov_dict[list(virusseq_add_ncov_dict.keys())[0]], \"\\n\")\n",
    "print(virusseq_add_ncovseqdict[list(virusseq_add_ncovseqdict.keys())[0]][:100], \"\\n\")\n",
    "print(drug_iddict[list(drug_iddict.keys())[0]], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TSV\n",
    "with open(\"DTI-data/drug_info.tsv\", \"r\") as f:\n",
    "    drug_info = csv.reader(f, delimiter = '\\t')\n",
    "    drug_info = list(drug_info)\n",
    "with open(\"DTI-data/final_Virus_DTI_add_organism.tsv\", \"r\") as f:\n",
    "    final_Virus_DTI_add_organism = csv.reader(f, delimiter = '\\t') \n",
    "    final_Virus_DTI_add_organism = list(final_Virus_DTI_add_organism)\n",
    "\n",
    "print(drug_info[0:2])\n",
    "print(\"\")\n",
    "print(final_Virus_DTI_add_organism[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KnowledgeGraphEmbedding expects 5 files\n",
    "\n",
    "# entities.dict - maps entities to ids\n",
    "# relations.dict - maps relations to ids\n",
    "# train.txt - entity id to relation id\n",
    "# valid.txt - can be blank\n",
    "# test.txt\n",
    "\n",
    "print(HDTI_net.shape)\n",
    "print(HDTI_net[0])\n",
    "\n",
    "print(\"!\", vdti_net.shape)\n",
    "print(\"!\", vdti_net[0])\n",
    "\n",
    "print(vhi_net.shape)\n",
    "print(vhi_net[0])\n",
    "\n",
    "#entities.dict\n",
    "\n",
    "DRUG_COUNT = 6255\n",
    "HUMAN_COUNT = 2567\n",
    "VIRUS_COUNT = 404\n",
    "\n",
    "sum_ = DRUG_COUNT + HUMAN_COUNT + VIRUS_COUNT\n",
    "\n",
    "HUMAN_OFFSET = 6255\n",
    "VIRUS_OFFSET = 6255 + 2567\n",
    "\n",
    "names = [\"vdti\", \"hdti\", \"vhi\", \"ppi\", \"drug_s\", \"human_s\", \"virus_s\"]\n",
    "vars = [vdti_net, HDTI_net, vhi_net, ppi_net, drug_simi_net, human, virusseq_add_ncov]\n",
    "lens = [len(arr) for arr in vars]\n",
    "#lens = [vdti_net.shape[0], HDTI_net.shape[0], vhi_net.shape[0], ppi_net.shape[0], drug_simi_net.shape[0], human_seq_dict.shape[0], virusseq_add_ncov.shape[0]]\n",
    "run_sum = [sum(lens[:i]) for i in range(1, len(names) + 1)]\n",
    "offset = {names[i]:run_sum[i] for i, _ in enumerate(names)}\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/entities.dict\", \"w\") as f:\n",
    "    for i in range(DRUG_COUNT + HUMAN_COUNT + VIRUS_COUNT):\n",
    "        f.write(str(i) + \"\\t\" + str(i) + \"\\n\")\n",
    "\n",
    "#relations.dict\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/relations.dict\", \"w\") as f:\n",
    "    f.write(\"0\\t0\\n\")\n",
    "    f.write(\"1\\t1\\n\")\n",
    "    f.write(\"2\\t2\\n\")\n",
    "    f.write(\"3\\t3\\n\")\n",
    "    f.write(\"4\\t4\\n\")\n",
    "    f.write(\"5\\t5\\n\")\n",
    "    f.write(\"6\\t6\")\n",
    "#with open(\"KnowledgeGraphEmbedding/data/C-19/entities.dict\" as f):\n",
    "\n",
    "#all.txt\n",
    "\n",
    "HIGH_SIM_THRES = 0.50\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/all.dict\", \"w\") as f:\n",
    "    #drug -> human\n",
    "    for (i, j), v in np.ndenumerate(HDTI_net):\n",
    "        assert(j + HUMAN_OFFSET < sum_)\n",
    "        if v:\n",
    "            f.write(str(i) + \"\\t\" + \"0\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "    #drug -> virus\n",
    "    i = 0\n",
    "    for (i, j), v in np.ndenumerate(vdti_net):\n",
    "        if v:\n",
    "            f.write(str(i) + \"\\t\" + \"1\"  + \"\\t\" +  str(j + VIRUS_OFFSET) + \"\\n\")  \n",
    "\n",
    "    #virus -> human\n",
    "    i = 0\n",
    "    for (i, j), v in np.ndenumerate(vhi_net):\n",
    "        assert(i + VIRUS_OFFSET < sum_)\n",
    "        assert(j + HUMAN_OFFSET < sum_)\n",
    "        if v:\n",
    "            f.write(str(i + VIRUS_OFFSET) + \"\\t\" + \"2\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")          \n",
    "\n",
    "    for (i, j), v in np.ndenumerate(ppi_net):\n",
    "\n",
    "        if v:\n",
    "            f.write(str(i + HUMAN_OFFSET) + \"\\t\" + \"3\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "\n",
    "    for (i, j), v in np.ndenumerate(drug_simi_net):\n",
    "        if v >= HIGH_SIM_THRES:\n",
    "            f.write(str(i) + \"\\t\" + \"4\"  + \"\\t\" + str(j) + \"\\n\")\n",
    "\n",
    "\n",
    "    for (i, j), v in np.ndenumerate(human):\n",
    "        if v >= HIGH_SIM_THRES:\n",
    "            f.write(str(i + HUMAN_OFFSET) + \"\\t\" + \"5\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "\n",
    "    for (i, j), v in np.ndenumerate(virusseq_add_ncov):\n",
    "        if v >= HIGH_SIM_THRES:\n",
    "            f.write(str(i + VIRUS_OFFSET) + \"\\t\" + \"6\"  + \"\\t\" + str(j + VIRUS_OFFSET) + \"\\n\")\n",
    "\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.85\n",
    "TRAIN_VAL_SPLIT  = 0.90\n",
    "\n",
    "print(\"start write\")\n",
    "\n",
    "with open(\"KnowledgeGraphEmbedding/data/C-19/all.dict\", \"r\") as f:\n",
    "    lst = f.readlines()\n",
    "    all_drug_indices = [i for i in range(DRUG_COUNT)]\n",
    "    train_t_drug_indices = random.sample(all_drug_indices, int(len(all_drug_indices) * TRAIN_TEST_SPLIT))\n",
    "    train_drug_indices   = random.sample(train_t_drug_indices, int(len(train_t_drug_indices) * TRAIN_VAL_SPLIT)) \n",
    "    #train_t = random.sample(lst, int(len(lst) * TRAIN_TEST_SPLIT))\n",
    "    #train   = random.sample(train_t, int(len(train_t) * TRAIN_VAL_SPLIT))\n",
    "    val_drug_indices  = [e for e in train_t_drug_indices if e not in train_drug_indices]\n",
    "    test_drug_indices = [e for e in all_drug_indices if e not in train_t_drug_indices]\n",
    "    assert(len(val_drug_indices) > 0 and len(test_drug_indices) > 0)\n",
    "    #train   = [e for e in lst if e.split(\"\\t\")[1] in train_drug_indices]\n",
    "    #val     = [e for e in lst if e.split(\"\\t\")[1] in val_drug_indices]\n",
    "    #test    = [e for e in lst if e.split(\"\\t\")[1] in test_drug_indices]\n",
    "    #assert disjoint\n",
    "    pass\n",
    "    print(lst[0].split(\"\\t\"))\n",
    "    print(lst[1].split(\"\\t\")[2].strip(\"\\n\"))\n",
    "    test  = [e for e in lst if  int(e.split(\"\\t\")[0].strip(\"\\n\")) in test_drug_indices\n",
    "                            and e.split(\"\\t\")[1] in [\"0\", \"1\"]]\n",
    "    val   = [e for e in lst if  int(e.split(\"\\t\")[0].strip(\"\\n\")) in val_drug_indices\n",
    "                            and e.split(\"\\t\")[1] in [\"0\", \"1\"]]\n",
    "    #train = [e for e in lst if  int(e.split(\"\\t\")[0].strip(\"\\n\")) not in (test_drug_indices + val_drug_indices)\n",
    "    #                        or  e.split(\"\\t\")[1]  not in [\"0\", \"1\"]]\n",
    "    train = [e for e in lst if e not in test and e not in val]\n",
    "    for e in [test, val, train]:\n",
    "        assert(len(e) > 0)\n",
    "    #train.txt\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/train.txt\", \"w+\") as f:\n",
    "        f.writelines(train)\n",
    "    #valid.txt\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/valid.txt\", \"w+\") as f:\n",
    "        f.writelines(val)\n",
    "    #test.txt\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/test.txt\",  \"w+\") as f:\n",
    "        f.writelines(test)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test\n",
    "# -lr 0.0001 --max_steps 150000 \\\n",
    "!CUDA_LAUNCH_BLOCKING=1 CUDA_VISIBLE_DEVICES=0 python -u KnowledgeGraphEmbedding/codes/run.py --do_train \\\n",
    " --cuda \\\n",
    " --do_valid \\\n",
    " --do_test \\\n",
    " --data_path KnowledgeGraphEmbedding/data/C-19 \\\n",
    " --model RotatE \\\n",
    " -n 256 -b 1024 -d 1000 \\\n",
    " -g 24.0 -a 1.0 -adv \\\n",
    " -lr 0.0001 --max_steps 1000 \\\n",
    " --n_targets 404 \\\n",
    " -save KnowledgeGraphEmbedding/models/RotatE_C-19_0 --test_batch_size 8 -de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitanaconda3virtualenv3d0bc2d7120949c09cb2d2669d3d31e4",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}