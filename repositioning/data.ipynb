{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import sys\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drug_iddict        final_Virus_DTI_add_organism.tsv  human_seq_dict.pkl    VDTI_net.npy           virusseq_add_ncov.pkl\n",
    "#drug_info.tsv      HDTI_net.npy                      human_seq_iddict.pkl  VHI_net.npy            virusseq_add_ncovseqdict.pkl\n",
    "#Drug_simi_net.npy  human.npy                         PPI_net.npy           virusseq_add_ncov.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NPY\n",
    "drug_simi_net = np.load(\"DTI-data/Drug_simi_net.npy\")\n",
    "print(drug_simi_net.shape)\n",
    "print(drug_simi_net[0])\n",
    "HDTI_net = np.load(\"DTI-data/HDTI_net.npy\")\n",
    "print(HDTI_net.shape)\n",
    "print(HDTI_net[0])\n",
    "human = np.load(\"DTI-data/human.npy\")\n",
    "print(human.shape)\n",
    "print(human[0])\n",
    "ppi_net = np.load(\"DTI-data/PPI_net.npy\")\n",
    "print(ppi_net.shape)\n",
    "print(ppi_net[0])\n",
    "#This is our ultimate target\n",
    "vdti_net = np.load(\"DTI-data/VDTI_net.npy\")\n",
    "print(\"!\", vdti_net.shape)\n",
    "print(\"!\", vdti_net[0])\n",
    "vhi_net = np.load(\"DTI-data/VHI_net.npy\")\n",
    "print(vhi_net.shape)\n",
    "print(vhi_net[0])\n",
    "virusseq_add_ncov = np.load(\"DTI-data/virusseq_add_ncov.npy\")\n",
    "print(virusseq_add_ncov.shape)\n",
    "print(virusseq_add_ncov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PICKLE\n",
    "with open(\"DTI-data/human_seq_dict.pkl\", 'rb') as f:\n",
    "    human_seq_dict = pickle.load(f)\n",
    "with open(\"DTI-data/human_seq_iddict.pkl\", 'rb') as f:    \n",
    "    human_seq_iddict = pickle.load(f)\n",
    "with open(\"DTI-data/virusseq_add_ncov.pkl\", 'rb') as f:\n",
    "    virusseq_add_ncov_dict = pickle.load(f)\n",
    "with open(\"DTI-data/virusseq_add_ncovseqdict.pkl\", 'rb') as f:\n",
    "    virusseq_add_ncovseqdict = pickle.load(f)\n",
    "with open(\"DTI-data/drug_iddict\", 'rb') as f:\n",
    "    drug_iddict = pickle.load(f)\n",
    "\n",
    "print(human_seq_dict[list(human_seq_dict.keys())[0]][:100], \"\\n\")\n",
    "print(human_seq_iddict[list(human_seq_iddict.keys())[0]], \"\\n\")\n",
    "print(virusseq_add_ncov_dict[list(virusseq_add_ncov_dict.keys())[0]], \"\\n\")\n",
    "print(virusseq_add_ncovseqdict[list(virusseq_add_ncovseqdict.keys())[0]][:100], \"\\n\")\n",
    "print(drug_iddict[list(drug_iddict.keys())[0]], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TSV\n",
    "with open(\"DTI-data/drug_info.tsv\", \"r\") as f:\n",
    "    drug_info = csv.reader(f, delimiter = '\\t')\n",
    "    drug_info = list(drug_info)\n",
    "with open(\"DTI-data/final_Virus_DTI_add_organism.tsv\", \"r\") as f:\n",
    "    final_Virus_DTI_add_organism = csv.reader(f, delimiter = '\\t') \n",
    "    final_Virus_DTI_add_organism = list(final_Virus_DTI_add_organism)\n",
    "\n",
    "print(drug_info[0:2])\n",
    "print(\"\")\n",
    "print(final_Virus_DTI_add_organism[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(iter=0, kfolds=10, seed=0):\n",
    "    # KnowledgeGraphEmbedding expects 5 files\n",
    "\n",
    "    # entities.dict - maps entities to ids\n",
    "    # relations.dict - maps relations to ids\n",
    "    # train.txt - entity id to relation id\n",
    "    # valid.txt - can be blank\n",
    "    # test.txt\n",
    "\n",
    "    #print(HDTI_net.shape)\n",
    "    #print(HDTI_net[0])\n",
    "\n",
    "    #print(\"!\", vdti_net.shape)\n",
    "    #print(\"!\", vdti_net[0])\n",
    "\n",
    "    #print(vhi_net.shape)\n",
    "    #print(vhi_net[0])\n",
    "\n",
    "    #entities.dict\n",
    "\n",
    "    DRUG_COUNT = 6255\n",
    "    HUMAN_COUNT = 2567\n",
    "    VIRUS_COUNT = 404\n",
    "\n",
    "    sum_ = DRUG_COUNT + HUMAN_COUNT + VIRUS_COUNT\n",
    "\n",
    "    HUMAN_OFFSET = 6255\n",
    "    VIRUS_OFFSET = 6255 + 2567\n",
    "\n",
    "    names = [\"vdti\", \"hdti\", \"vhi\", \"ppi\", \"drug_s\", \"human_s\", \"virus_s\"]\n",
    "    vars = [vdti_net, HDTI_net, vhi_net, ppi_net, drug_simi_net, human, virusseq_add_ncov]\n",
    "    lens = [len(arr) for arr in vars]\n",
    "    #lens = [vdti_net.shape[0], HDTI_net.shape[0], vhi_net.shape[0], ppi_net.shape[0], drug_simi_net.shape[0],  uman_seq_dict.shape[0], virusseq_add_ncov.shape[0]]\n",
    "    run_sum = [sum(lens[:i]) for i in range(1, len(names) + 1)]\n",
    "    offset = {names[i]:run_sum[i] for i, _ in enumerate(names)}\n",
    "\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/entities.dict\", \"w\") as f:\n",
    "        for i in range(DRUG_COUNT + HUMAN_COUNT + VIRUS_COUNT):\n",
    "            f.write(str(i) + \"\\t\" + str(i) + \"\\n\")\n",
    "\n",
    "    #relations.dict\n",
    "\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/relations.dict\", \"w\") as f:\n",
    "        f.write(\"0\\t0\\n\")\n",
    "        f.write(\"1\\t1\\n\")\n",
    "        f.write(\"2\\t2\\n\")\n",
    "        f.write(\"3\\t3\\n\")\n",
    "        f.write(\"4\\t4\\n\")\n",
    "        f.write(\"5\\t5\\n\")\n",
    "        f.write(\"6\\t6\")\n",
    "    #with open(\"KnowledgeGraphEmbedding/data/C-19/entities.dict\" as f):\n",
    "\n",
    "    #all.txt\n",
    "\n",
    "    HIGH_SIM_THRES = 0.5\n",
    "\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/all.dict\", \"w\") as f:\n",
    "        #drug -> human\n",
    "        for (i, j), v in np.ndenumerate(HDTI_net):\n",
    "            assert(j + HUMAN_OFFSET < sum_)\n",
    "            if v:\n",
    "                f.write(str(i) + \"\\t\" + \"0\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "        #drug -> virus\n",
    "        i = 0\n",
    "        for (i, j), v in np.ndenumerate(vdti_net):\n",
    "            if v:\n",
    "                f.write(str(i) + \"\\t\" + \"1\"  + \"\\t\" +  str(j + VIRUS_OFFSET) + \"\\n\")  \n",
    "\n",
    "        #virus -> human\n",
    "        i = 0\n",
    "        for (i, j), v in np.ndenumerate(vhi_net):\n",
    "            assert(i + VIRUS_OFFSET < sum_)\n",
    "            assert(j + HUMAN_OFFSET < sum_)\n",
    "            if v:\n",
    "                f.write(str(i + VIRUS_OFFSET) + \"\\t\" + \"2\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")          \n",
    "\n",
    "        for (i, j), v in np.ndenumerate(ppi_net):\n",
    "            assert(i + HUMAN_OFFSET < sum_)\n",
    "            assert(j + HUMAN_OFFSET < sum_)\n",
    "            if v:\n",
    "                f.write(str(i + HUMAN_OFFSET) + \"\\t\" + \"3\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "\n",
    "        for (i, j), v in np.ndenumerate(drug_simi_net):\n",
    "            assert(i  < sum_)\n",
    "            assert(j  < sum_)\n",
    "            if v >= HIGH_SIM_THRES:\n",
    "                f.write(str(i) + \"\\t\" + \"4\"  + \"\\t\" + str(j) + \"\\n\")\n",
    "\n",
    "\n",
    "        for (i, j), v in np.ndenumerate(human):\n",
    "            assert(i + HUMAN_OFFSET < sum_)\n",
    "            assert(j + HUMAN_OFFSET < sum_)\n",
    "            if v >= HIGH_SIM_THRES:\n",
    "                f.write(str(i + HUMAN_OFFSET) + \"\\t\" + \"5\"  + \"\\t\" + str(j + HUMAN_OFFSET) + \"\\n\")\n",
    "\n",
    "\n",
    "        for (i, j), v in np.ndenumerate(virusseq_add_ncov):\n",
    "            assert(i + VIRUS_OFFSET < sum_)\n",
    "            assert(j + VIRUS_OFFSET < sum_)\n",
    "            if v >= HIGH_SIM_THRES:\n",
    "                f.write(str(i + VIRUS_OFFSET) + \"\\t\" + \"6\"  + \"\\t\" + str(j + VIRUS_OFFSET) + \"\\n\")\n",
    "\n",
    "    TRAIN_TEST_SPLIT = 0.85\n",
    "    TRAIN_VAL_SPLIT  = 0.90\n",
    "\n",
    "    print(\"start write\")\n",
    "\n",
    "    #TODO: rename drug variables to virus\n",
    "    with open(\"KnowledgeGraphEmbedding/data/C-19/all.dict\", \"r\") as f:\n",
    "        lst = f.readlines()\n",
    "        all_drug_indices = [i for i in range(VIRUS_OFFSET, VIRUS_COUNT + VIRUS_OFFSET)]\n",
    "        kf = KFold(n_splits=kfolds, shuffle=True, random_state=seed)\n",
    "        train_t_drug_indices,  test_drug_indices = list(kf.split(all_drug_indices))[iter]\n",
    "\n",
    "        #kfold indices -> drug indices\n",
    "        train_t_drug_indices = [all_drug_indices[i] for i in train_t_drug_indices]\n",
    "        test_drug_indices    = [all_drug_indices[i] for i in test_drug_indices]\n",
    "\n",
    "        \"\"\"\n",
    "        kf2 = KFold(n_splits=kfolds, shuffle=True, random_state=seed)\n",
    "        list_of_tuple_of_list_of_indices = list(kf.split(train_t_drug_indices))\n",
    "        train_drug_indices =  [tup[0] for tup in list_of_tuple_of_list_of_indices]\n",
    "        val_drug_indices   =  [tup[1] for tup in list_of_tuple_of_list_of_indices]\n",
    "        train_drug_indices =  [index for idxlist in train_drug_indices for index in idxlist]\n",
    "        val_drug_indices   =  [index for idxlist in val_drug_indices   for index in idxlist]\n",
    "        \"\"\"\n",
    "\n",
    "        #create validation set\n",
    "        #remove validation data from train set\n",
    "        val_drug_indices   = [i for i in train_t_drug_indices[::kfolds]]\n",
    "        train_drug_indices = [i for i in train_t_drug_indices if i not in val_drug_indices]\n",
    "\n",
    "        print(\"===\")\n",
    "        print(\"test indices\", test_drug_indices)\n",
    "        print(\"val indices\", val_drug_indices)\n",
    "        print(\"train indices sample\", train_drug_indices[:100])\n",
    "        print(\"===\")\n",
    "\n",
    "        assert(len(test_drug_indices) > 0 and len(train_t_drug_indices) > 0)\n",
    "        #assert disjoint and span\n",
    "        pass\n",
    "        print(lst[0].split(\"\\t\"))\n",
    "        print(lst[1].split(\"\\t\")[2].strip(\"\\n\"))\n",
    "\n",
    "        test  = [e for e in lst if  int(e.split(\"\\t\")[2].strip(\"\\n\")) in test_drug_indices and e.split(\"\\t\")[1] in [\"1\"]]\n",
    "        val   = [e for e in lst if  int(e.split(\"\\t\")[2].strip(\"\\n\")) in val_drug_indices  and e.split(\"\\t\")[1] in [\"1\"]]\n",
    "        train = [e for e in lst if e not in test and e not in val]\n",
    "        \n",
    "        for e in [test, train, val]:\n",
    "            assert(len(e) > 0)\n",
    "        #train.txt\n",
    "        with open(\"KnowledgeGraphEmbedding/data/C-19/train.txt\", \"w+\") as f:\n",
    "            f.writelines(train)\n",
    "        #valid.txt\n",
    "        with open(\"KnowledgeGraphEmbedding/data/C-19/valid.txt\", \"w+\") as f:\n",
    "            f.writelines(val) #val\n",
    "        #test.txt\n",
    "        with open(\"KnowledgeGraphEmbedding/data/C-19/test.txt\",  \"w+\") as f:\n",
    "            f.writelines(test)\n",
    "\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test\n",
    "# -lr 0.0001 --max_steps 150000 \\\n",
    "#    --do_valid \\\n",
    "kfolds = 10\n",
    "seed   = 42\n",
    "\n",
    "#Test gamma\n",
    "#Reduce dimension\n",
    "#Vary learning rate\n",
    "#Max steps is less important\n",
    "#Vary Modelee\n",
    "#overwrites log each iteration!\n",
    "#    -lr 0.0001 --max_steps 5000 \\\n",
    "for i in range(kfolds):\n",
    "    prepare_data(i, kfolds, seed)\n",
    "\n",
    "    if i % 4 == 0:\n",
    "        !CUDA_VISIBLE_DEVICES=0 python -u KnowledgeGraphEmbedding/codes/run.py --do_train \\\n",
    "        --cuda \\\n",
    "        --do_test \\\n",
    "        --data_path KnowledgeGraphEmbedding/data/C-19 \\\n",
    "        --model RotatE \\\n",
    "        -n 256 -b 1024 -d 100 \\\n",
    "        -g 240.0 -a 2.0 -adv \\\n",
    "        -lr 0.0001 --max_steps 5000 \\\n",
    "        --n_targets 404 \\\n",
    "        --do_valid \\\n",
    "        --valid_steps 1000 \\\n",
    "        -save KnowledgeGraphEmbedding/models/RotatE_C-19_0 --test_batch_size 8 -de  2>&1| tee -a kge_log.txt\n",
    "\n",
    "    elif i % 4 == 1:\n",
    "        !CUDA_VISIBLE_DEVICES=0 python -u KnowledgeGraphEmbedding/codes/run.py --do_train \\\n",
    "        --cuda \\\n",
    "        --do_test \\\n",
    "        --data_path KnowledgeGraphEmbedding/data/C-19 \\\n",
    "        --model RotatE \\\n",
    "        -n 256 -b 1024 -d 100 \\\n",
    "        -g 24.0 -a 1.0 -adv \\\n",
    "        -lr 0.0001 --max_steps 5000 \\\n",
    "        --n_targets 404 \\\n",
    "        --do_valid \\\n",
    "        --valid_steps 1000 \\\n",
    "        -save KnowledgeGraphEmbedding/models/RotatE_C-19_0 --test_batch_size 8 -de  2>&1| tee -a kge_log.txt\n",
    "\n",
    "    elif i % 4 == 2:\n",
    "        !CUDA_VISIBLE_DEVICES=0 python -u KnowledgeGraphEmbedding/codes/run.py --do_train \\\n",
    "        --cuda \\\n",
    "        --do_test \\\n",
    "        --data_path KnowledgeGraphEmbedding/data/C-19 \\\n",
    "        --model RotatE \\\n",
    "        -n 256 -b 1024 -d 1000 \\\n",
    "        -g 3.0 -a 5.0 -adv \\\n",
    "        -lr 0.0001 --max_steps 5000 \\\n",
    "        --n_targets 404 \\\n",
    "        --do_valid \\\n",
    "        --valid_steps 1000 \\\n",
    "        -save KnowledgeGraphEmbedding/models/RotatE_C-19_0 --test_batch_size 8 -de  2>&1| tee -a kge_log.txt\n",
    "\n",
    "    elif i % 4 == 3:\n",
    "        !CUDA_VISIBLE_DEVICES=0 python -u KnowledgeGraphEmbedding/codes/run.py --do_train \\\n",
    "        --cuda \\\n",
    "        --do_test \\\n",
    "        --data_path KnowledgeGraphEmbedding/data/C-19 \\\n",
    "        --model RotatE \\\n",
    "        -n 256 -b 1024 -d 1000 \\\n",
    "        -g 96 -a 1.0 -adv \\\n",
    "        -lr 0.0001 --max_steps 20000 \\\n",
    "        --n_targets 404 \\\n",
    "        --do_valid \\\n",
    "        --valid_steps 1000 \\\n",
    "        -save KnowledgeGraphEmbedding/models/RotatE_C-19_0 --test_batch_size 8 -de  2>&1| tee -a kge_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture output\n",
    "with open(\"KnowledgeGraphEmbedding/models/RotatE_C-19_0/train.log\") as f:\n",
    "    output = f.readlines()\n",
    "out = output\n",
    "#print(out)\n",
    "print(out)\n",
    "res1 = [line for line in out if \"auc_pr\" in line]\n",
    "res2 = [line for line in out if \"auc_roc\" in line]\n",
    "#2020-05-29 10:58:05,858 INFO     Test auc_pr at step 9999: 0.817098\n",
    "#2020-05-29 10:58:05,858 INFO     Test auc_roc at step 9999: 0.780551\n",
    "\n",
    "#print(res)\n",
    "#print(res1)\n",
    "res1 = [re.findall(\"\\d+\\.\\d+\", r) for r in res1]\n",
    "res2 = [re.findall(\"\\d+\\.\\d+\", r) for r in res2]\n",
    "\n",
    "print(res1)\n",
    "print(res2)\n",
    "\n",
    "#deb = [line for line in out if \"kfold\" in line]\n",
    "\n",
    "#print(deb)\n",
    "#clear buffers\n",
    "#output = \"\"\n",
    "#out    = \"\"\n",
    "#res    = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = \"\"\"2020-05-30 17:28:46,433 INFO     Test auc_pr at step 19999: 0.716268\n",
    "2020-05-30 17:28:46,433 INFO     Test auc_roc at step 19999: 0.682861\n",
    "2020-05-30 19:05:18,762 INFO     Test auc_pr at step 19999: 0.759156\n",
    "2020-05-30 19:05:18,762 INFO     Test auc_roc at step 19999: 0.706657\n",
    "2020-05-30 20:41:21,922 INFO     Test auc_pr at step 19999: 0.739043\n",
    "2020-05-30 20:41:21,922 INFO     Test auc_roc at step 19999: 0.647360\n",
    "2020-05-30 22:17:48,734 INFO     Test auc_pr at step 19999: 0.728497\n",
    "2020-05-30 22:17:48,734 INFO     Test auc_roc at step 19999: 0.640756\n",
    "2020-05-30 23:56:06,703 INFO     Test auc_pr at step 19999: 0.676069\n",
    "2020-05-30 23:56:06,703 INFO     Test auc_roc at step 19999: 0.655680\n",
    "2020-05-31 01:34:04,867 INFO     Test auc_pr at step 19999: 0.645229\n",
    "2020-05-31 01:34:04,867 INFO     Test auc_roc at step 19999: 0.603482\n",
    "2020-05-31 03:11:51,151 INFO     Test auc_pr at step 19999: 0.736085\n",
    "2020-05-31 03:11:51,151 INFO     Test auc_roc at step 19999: 0.701004\n",
    "2020-05-31 04:48:40,105 INFO     Test auc_pr at step 19999: 0.730914\n",
    "2020-05-31 04:48:40,105 INFO     Test auc_roc at step 19999: 0.734637\n",
    "2020-05-31 06:25:25,569 INFO     Test auc_pr at step 19999: 0.802390\n",
    "2020-05-31 06:25:25,569 INFO     Test auc_roc at step 19999: 0.758581\n",
    "2020-05-31 08:02:56,224 INFO     Test auc_pr at step 19999: 0.787228\n",
    "2020-05-31 08:02:56,224 INFO     Test auc_roc at step 19999: 0.762826\n",
    "\"\"\"\n",
    "\n",
    "res = re.findall(\"\\d+.\\d+\\n\", OUT)\n",
    "auc_prs = [float(e.strip(\"\\n\")) for e in res[::2]]\n",
    "auc_roc = [float(e.strip(\"\\n\")) for e in res[1::2]]\n",
    "\n",
    "print(sum(auc_prs)/len(auc_prs))\n",
    "print(sum(auc_roc)/len(auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37",
   "display_name": "Python 3.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
